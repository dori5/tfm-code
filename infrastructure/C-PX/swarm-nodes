# Build the two images needed: 1 for hadoop and 1 for spark master and workers (we are inside PD (pseudo distributed) directory)

# Login into docker

docker login

-------------------------------------------------------------------------------------------------

# Spark master and workers

cd spark
docker build -t medu5a/spark-master-worker .

# Push the spark image to docker-hub

docker push medu5a/spark-master-worker

# Hadoop

cd hadoop
docker build -t tfm_hadoop .

-------------------------------------------------------------------------------------------------

# Docker Machine for Consul

docker-machine create -d virtualbox consul-machine

#Running pre-create checks...
#Creating machine...
#(consul-machine) Copying /root/.docker/machine/cache/boot2docker.iso to /root/.docker/machine/machines/consul-machine/boot2docker.iso...
#(consul-machine) Creating VirtualBox VM...
#(consul-machine) Creating SSH key...
#(consul-machine) Starting the VM...
#(consul-machine) Check network to re-create if needed...
#(consul-machine) Waiting for an IP...
#Waiting for machine to be running, this may take a few minutes...
#Detecting operating system of created instance...
#Waiting for SSH to be available...
#Detecting the provisioner...
#Provisioning with boot2docker...
#Copying certs to the local machine directory...
#Copying certs to the remote machine...
#Setting Docker configuration on the remote daemon...
#Checking connection to Docker...
#Docker is up and running!
#To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env consul-machine

-------------------------------------------------------------------------------------------------

# Start Consul

docker $(docker-machine config consul-machine) \
run -d --restart=always -p "8500:8500" -h "consul" \
progrium/consul -server -bootstrap

#Unable to find image 'progrium/consul:latest' locally
#latest: Pulling from progrium/consul
#c862d82a67a2: Pull complete 
#0e7f3c08384e: Pull complete 
#0e221e32327a: Pull complete 
#09a952464e47: Pull complete 
#60a1b927414d: Pull complete 
#4c9f46b5ccce: Pull complete 
#417d86672aa4: Pull complete 
#b0d47ad24447: Pull complete 
#fd5300bd53f0: Pull complete 
#a3ed95caeb02: Pull complete 
#d023b445076e: Pull complete 
#ba8851f89e33: Pull complete 
#5d1cefca2a28: Pull complete 
#Digest: sha256:8cc8023462905929df9a79ff67ee435a36848ce7a10f18d6d0faba9306b97274
#Status: Downloaded newer image for progrium/consul:latest
#0d3f1e9a31e5c06aa286e1af6f632572ff4b513bc981785844321811de4b086b

-------------------------------------------------------------------------------------------------

# Docker Swarm master

docker-machine create -d virtualbox --swarm --swarm-master \
--swarm-discovery="consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-store=consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-advertise=eth1:2376" swarm-manager

#Running pre-create checks...
#Creating machine...
#(swarm-manager) Copying /root/.docker/machine/cache/boot2docker.iso to /root/.docker/machine/machines/swarm-manager/boot2docker.iso...
#(swarm-manager) Creating VirtualBox VM...
#(swarm-manager) Creating SSH key...
#(swarm-manager) Starting the VM...
#(swarm-manager) Check network to re-create if needed...
#(swarm-manager) Waiting for an IP...
#Waiting for machine to be running, this may take a few minutes...
#Detecting operating system of created instance...
#Waiting for SSH to be available...
#Detecting the provisioner...
#Provisioning with boot2docker...
#Copying certs to the local machine directory...
#Copying certs to the remote machine...
#Setting Docker configuration on the remote daemon...
#Configuring swarm...
#Checking connection to Docker...
#Docker is up and running!
#To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env swarm-manager

-------------------------------------------------------------------------------------------------

# Docker Swarm swarm-node-hadoop

docker-machine create -d virtualbox --swarm \
--swarm-discovery="consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-store=consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-advertise=eth1:2376" swarm-node-hadoop

#Running pre-create checks...
#Creating machine...
#(swarm-node-hadoop) Copying /root/.docker/machine/cache/boot2docker.iso to /root/.docker/machine/machines/swarm-node-hadoop/boot2docker.iso...
#(swarm-node-hadoop) Creating VirtualBox VM...
#(swarm-node-hadoop) Creating SSH key...
#(swarm-node-hadoop) Starting the VM...
#(swarm-node-hadoop) Check network to re-create if needed...
#(swarm-node-hadoop) Waiting for an IP...
#Waiting for machine to be running, this may take a few minutes...
#Detecting operating system of created instance...
#Waiting for SSH to be available...
#Detecting the provisioner...
#Provisioning with boot2docker...
#Copying certs to the local machine directory...
#Copying certs to the remote machine...
#Setting Docker configuration on the remote daemon...
#Configuring swarm...
#Checking connection to Docker...
#Docker is up and running!
#To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env swarm-node-hadoop

-------------------------------------------------------------------------------------------------

# Docker Swarm swarm-node-01 (for one worker)

docker-machine create -d virtualbox --swarm \
--swarm-discovery="consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-store=consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-advertise=eth1:2376" --engine-label role=worker swarm-node-01

-------------------------------------------------------------------------------------------------

# Docker Swarm swarm-node-02 (for the other worker)

docker-machine create -d virtualbox --swarm \
--swarm-discovery="consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-store=consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-advertise=eth1:2376" --engine-label role=worker swarm-node-02

-------------------------------------------------------------------------------------------------

# List the existent docker machines 

docker-machine ls

# NAME                ACTIVE   DRIVER       STATE     URL                         SWARM                    DOCKER        ERRORS
# consul-machine      -        virtualbox   Running   tcp://192.168.99.100:2376                            v17.03.0-ce   
# swarm-manager       -        virtualbox   Running   tcp://192.168.99.101:2376   swarm-manager (master)   v17.03.0-ce   
# swarm-node-01       -        virtualbox   Running   tcp://192.168.99.103:2376   swarm-manager            v17.03.0-ce   
# swarm-node-02       -        virtualbox   Running   tcp://192.168.99.104:2376   swarm-manager            v17.03.0-ce   
# swarm-node-hadoop   -        virtualbox   Running   tcp://192.168.99.102:2376   swarm-manager            v17.03.0-ce   

-------------------------------------------------------------------------------------------------

# Pull the image for the spark master / workers to all containers

docker pull medu5a/spark-master-worker

-------------------------------------------------------------------------------------------------

# Configure to use Docker Swarm cluster

eval "$(docker-machine env --swarm swarm-manager)"

# Create master and hadoop containers inside their VMs

docker-compose up -d spark-master hadoop

# Creating pd_spark-master_1
# Creating pd_hadoop_1

-------------------------------------------------------------------------------------------------

# Scale services (the workers in this case)

docker-compose scale spark-worker=4 

# Creating and starting pd_spark-worker_1 ... done
# Creating and starting pd_spark-worker_2 ... done
# Creating and starting pd_spark-worker_3 ... done
# Creating and starting pd_spark-worker_4 ... done

-------------------------------------------------------------------------------------------------

# Docker info

eval "$(docker-machine env --swarm swarm-manager)"

docker info

# Containers: 11
#  Running: 10
#  Paused: 0
#  Stopped: 1
# Images: 10
# Server Version: swarm/1.2.6
# Role: primary
# Strategy: spread
# Filters: health, port, containerslots, dependency, affinity, constraint, whitelist
# Nodes: 4
#  swarm-manager: 192.168.99.101:2376
#   └ ID: NKGS:X3HF:P6M5:QMEL:GODA:RPSI:HCNQ:5L5B:MEY7:72IZ:YTAV:3SWU
#   └ Status: Healthy
#   └ Containers: 3 (3 Running, 0 Paused, 0 Stopped)
#   └ Reserved CPUs: 0 / 1
#   └ Reserved Memory: 0 B / 1.021 GiB
#   └ Labels: kernelversion=4.4.57-boot2docker, operatingsystem=Boot2Docker 17.03.1-ce (TCL 7.2); HEAD : 4c264fa - Tue Mar 28 21:11:51 UTC 2017, provider=virtualbox, storagedriver=aufs
#   └ UpdatedAt: 2017-04-04T17:53:16Z
#   └ ServerVersion: 17.03.1-ce
#  swarm-node-01: 192.168.99.103:2376
#   └ ID: 2DVB:7RNJ:BFJC:S55X:IFV2:HUIW:D2O4:EOLS:MP43:CROL:SOCP:C4XV
#   └ Status: Healthy
#   └ Containers: 3 (3 Running, 0 Paused, 0 Stopped)
#   └ Reserved CPUs: 0 / 1
#   └ Reserved Memory: 0 B / 1.021 GiB
#   └ Labels: kernelversion=4.4.57-boot2docker, operatingsystem=Boot2Docker 17.03.1-ce (TCL 7.2); HEAD : 4c264fa - Tue Mar 28 21:11:51 UTC 2017, provider=virtualbox, role=worker, storagedriver=aufs
#   └ UpdatedAt: 2017-04-04T17:53:14Z
#   └ ServerVersion: 17.03.1-ce
#  swarm-node-02: 192.168.99.104:2376
#   └ ID: AHFL:5AXG:A3NX:UYIT:PBPW:Q6NN:SJ4C:VVTY:CFNL:YRW5:BMLA:VCJS
#   └ Status: Healthy
#   └ Containers: 3 (3 Running, 0 Paused, 0 Stopped)
#   └ Reserved CPUs: 0 / 1
#   └ Reserved Memory: 0 B / 1.021 GiB
#   └ Labels: kernelversion=4.4.57-boot2docker, operatingsystem=Boot2Docker 17.03.1-ce (TCL 7.2); HEAD : 4c264fa - Tue Mar 28 21:11:51 UTC 2017, provider=virtualbox, role=worker, storagedriver=aufs
#   └ UpdatedAt: 2017-04-04T17:53:19Z
#   └ ServerVersion: 17.03.1-ce
#  swarm-node-hadoop: 192.168.99.102:2376
#   └ ID: KYSV:UK73:7QNG:WAZS:73HN:F6YL:VVG6:UNJV:6WEP:RRWF:QXL6:BIY4
#   └ Status: Healthy
#   └ Containers: 2 (2 Running, 0 Paused, 0 Stopped)
#   └ Reserved CPUs: 0 / 1
#   └ Reserved Memory: 0 B / 1.021 GiB
#   └ Labels: kernelversion=4.4.57-boot2docker, operatingsystem=Boot2Docker 17.03.1-ce (TCL 7.2); HEAD : 4c264fa - Tue Mar 28 21:11:51 UTC 2017, provider=virtualbox, storagedriver=aufs
#   └ UpdatedAt: 2017-04-04T17:53:25Z
#   └ ServerVersion: 17.03.1-ce

-------------------------------------------------------------------------------------------------

# Enter the hadoop container

docker exec -it <containerID> /bin/bash

# Check Hadoop daemons running in the container

jps

118 NameNode
530 ResourceManager
618 NodeManager
231 DataNode
385 SecondaryNameNode
672 JobHistoryServer
3807 Jps

# Check files exist inside the HDFS

#hdfs dfs -ls hdfs://hadoop:9000/data/
#Found 1 items
#-rw-r--r--   3 root supergroup     625507 2017-07-03 00:57 hdfs://hadoop:9000/data/original_dataset.txt

-------------------------------------------------------------------------------------------------

# Enter the spark-master container

docker exec -it pd_spark-master_1 /bin/bash

# Execute SparkPi example application

spark-submit --class org.apache.spark.examples.SparkPi \
--deploy-mode client --master spark://spark-master:7077 \
examples/jars/spark-examples_2.11-2.1.0.jar 1000

-------------------------------------------------------------------------------------------------

# All-in

docker-machine create -d virtualbox consul-machine && \
docker $(docker-machine config consul-machine) \
run -d --restart=always -p "8500:8500" -h "consul" \
progrium/consul -server -bootstrap && \
docker-machine create -d virtualbox --swarm --swarm-master \
--swarm-discovery="consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-store=consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-advertise=eth1:2376" swarm-manager && \
docker-machine create -d virtualbox --swarm \
--swarm-discovery="consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-store=consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-advertise=eth1:2376" swarm-node-hadoop && \
docker-machine create -d virtualbox --swarm \
--swarm-discovery="consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-store=consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-advertise=eth1:2376" --engine-label role=worker swarm-node-01 && \
docker-machine create -d virtualbox --swarm \
--swarm-discovery="consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-store=consul://$(docker-machine ip consul-machine):8500" \
--engine-opt="cluster-advertise=eth1:2376" --engine-label role=worker swarm-node-02 && \
eval "$(docker-machine env --swarm swarm-manager)" && \
docker-compose up -d spark-master hadoop && \
docker-compose scale spark-worker=4
